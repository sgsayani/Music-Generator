# e-MusicGen: An Integrated Stack Ensemble Model for Music Generation 

Over the past few decades, the wave of deep learning technology has extended its application in the domain of creative content generation. The aim of this study is to predict music using a deep learning model without any human intervention. To accomplish this, an integrated stack ensemble model is developed. This proposed model outperforms the standard RNN, LSTM, CNN and hybrid models in terms of accuracy and loss in expense of higher time complexity. This model uses a musical instrument digital interface (MIDI) file to learn and understand the sequence of a music piece. Data pre-processing need to be performed before feeding the data to the model. The stack ensemble model has the potential to remember previous information from a music sequence and predict the next sequence. This article imparts a brief description of the hybrid model architecture and stack ensemble model architecture along with their performance comparison in terms of accuracy, loss, time complexity and a comparison of predicted and tested music sequences.

# Keywords â€“ RNN | CNN | LSTM |  Hybrid model |  Stack ensemble model |  Music generation

# Link for web-app: https://hrithik0the0research-music-generate-web-interface-gpv6un.streamlit.app/ 
(Note: It can be seen that the web app is in sleep mode, as it automatically detects not traffic, click "Yes, get this app back up!" and wait some moments it will be opened automatically) 

# Video of the project: 



https://github.com/sgsayani/Music-Generator/assets/71175346/9c135e4f-722d-4aca-b02a-61c4ef905345

